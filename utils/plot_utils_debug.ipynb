{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import trange\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import datetime\n",
    "\n",
    "\n",
    "def gather_features(model, testset):\n",
    "    gathered_token_classes = []\n",
    "    gathered_token_features = []\n",
    "    gathered_token_features_0 = []\n",
    "    gathered_token_features_1 = []\n",
    "    gathered_token_features_2 = []\n",
    "    gathered_token_features_3 = []\n",
    "    gathered_token_features_4 = []\n",
    "\n",
    "    for j in trange(testset.batch_count):\n",
    "        sentence_ids, bert_tokens, masks, word_spans, tagging_matrices, tokenized, cl_masks, token_classes = testset.get_batch(j)\n",
    "        with torch.no_grad():\n",
    "            features = model.bert(bert_tokens, masks)\n",
    "            # print(features['last_hidden_state'].shape)\n",
    "            features = features['last_hidden_state']\n",
    "\n",
    "        gathered_token_features.append(features)\n",
    "        gathered_token_classes.extend(token_classes)\n",
    "\n",
    "    # gathered_token_features = torch.cat(gathered_token_features, dim=0)\n",
    "    # print(gathered_token_features)\n",
    "\n",
    "    for features, token_classes in zip(gathered_token_features, gathered_token_classes):\n",
    "        # print(features.shape, token_classes)\n",
    "        L = len(token_classes)\n",
    "        # print(L)\n",
    "        features = features[:, :L, :]\n",
    "        token_classes = np.array(token_classes)\n",
    "        \n",
    "        # print(features.shape)\n",
    "        # print([token_classes == 0])\n",
    "        token_class_0 = features[:, token_classes == 0, :]\n",
    "        # print(token_class_0.shape)\n",
    "        token_class_1 = features[:, token_classes == 1, :]\n",
    "        token_class_2 = features[:, token_classes == 2, :]\n",
    "        token_class_3 = features[:, token_classes == 3, :]\n",
    "        token_class_4 = features[:, token_classes == 4, :]\n",
    "\n",
    "        gathered_token_features_0.extend(token_class_0)\n",
    "        gathered_token_features_1.extend(token_class_1)\n",
    "        gathered_token_features_2.extend(token_class_2)\n",
    "        gathered_token_features_3.extend(token_class_3)\n",
    "        gathered_token_features_4.extend(token_class_4)\n",
    "\n",
    "    gathered_token_features_0 = torch.cat(gathered_token_features_0, dim=0).cpu().numpy()\n",
    "    gathered_token_features_1 = torch.cat(gathered_token_features_1, dim=0).cpu().numpy()\n",
    "    gathered_token_features_2 = torch.cat(gathered_token_features_2, dim=0).cpu().numpy()\n",
    "    gathered_token_features_3 = torch.cat(gathered_token_features_3, dim=0).cpu().numpy()\n",
    "    gathered_token_features_4 = torch.cat(gathered_token_features_4, dim=0).cpu().numpy()\n",
    "\n",
    "    return gathered_token_features_0, gathered_token_features_1, gathered_token_features_2, gathered_token_features_3, gathered_token_features_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import trange\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import datetime\n",
    "\n",
    "\n",
    "def gather_features(model, testset):\n",
    "    gathered_token_classes = []\n",
    "    gathered_token_features = []\n",
    "    gathered_token_features_0 = []\n",
    "    gathered_token_features_1 = []\n",
    "    gathered_token_features_2 = []\n",
    "    gathered_token_features_3 = []\n",
    "    gathered_token_features_4 = []\n",
    "\n",
    "    for j in trange(testset.batch_count):\n",
    "        sentence_ids, bert_tokens, masks, word_spans, tagging_matrices, tokenized, cl_masks, token_classes = testset.get_batch(j)\n",
    "        with torch.no_grad():\n",
    "            features = model.bert(bert_tokens, masks)\n",
    "            # print(features['last_hidden_state'].shape)\n",
    "            features = features['last_hidden_state']\n",
    "\n",
    "        gathered_token_features.append(features)\n",
    "        gathered_token_classes.extend(token_classes)\n",
    "\n",
    "    # gathered_token_features = torch.cat(gathered_token_features, dim=0)\n",
    "    # print(gathered_token_features)\n",
    "\n",
    "    for features, token_classes in zip(gathered_token_features, gathered_token_classes):\n",
    "        # print(features.shape, token_classes)\n",
    "        L = len(token_classes)\n",
    "        # print(L)\n",
    "        features = features[:, :L, :]\n",
    "        token_classes = np.array(token_classes)\n",
    "        \n",
    "        # print(features.shape)\n",
    "        # print([token_classes == 0])\n",
    "        token_class_0 = features[:, token_classes == 0, :]\n",
    "        # print(token_class_0.shape)\n",
    "        token_class_1 = features[:, token_classes == 1, :]\n",
    "        token_class_2 = features[:, token_classes == 2, :]\n",
    "        token_class_3 = features[:, token_classes == 3, :]\n",
    "        token_class_4 = features[:, token_classes == 4, :]\n",
    "\n",
    "        gathered_token_features_0.extend(token_class_0)\n",
    "        gathered_token_features_1.extend(token_class_1)\n",
    "        gathered_token_features_2.extend(token_class_2)\n",
    "        gathered_token_features_3.extend(token_class_3)\n",
    "        gathered_token_features_4.extend(token_class_4)\n",
    "\n",
    "    gathered_token_features_0 = torch.cat(gathered_token_features_0, dim=0).cpu().numpy()\n",
    "    gathered_token_features_1 = torch.cat(gathered_token_features_1, dim=0).cpu().numpy()\n",
    "    gathered_token_features_2 = torch.cat(gathered_token_features_2, dim=0).cpu().numpy()\n",
    "    gathered_token_features_3 = torch.cat(gathered_token_features_3, dim=0).cpu().numpy()\n",
    "    gathered_token_features_4 = torch.cat(gathered_token_features_4, dim=0).cpu().numpy()\n",
    "\n",
    "    return gathered_token_features_0, gathered_token_features_1, gathered_token_features_2, gathered_token_features_3, gathered_token_features_4\n",
    "\n",
    "\n",
    "\n",
    "def plot_pca(gathered_token_class_0, gathered_token_class_1, gathered_token_class_2, gathered_token_class_3, gathered_token_class_4, epoch):\n",
    "\n",
    "    # random sample N points for each class, where N is the number of points in the smallest class\n",
    "    gather = [gathered_token_class_0, \n",
    "            gathered_token_class_1, \n",
    "            gathered_token_class_2, \n",
    "            gathered_token_class_3, \n",
    "            gathered_token_class_4]\n",
    "    c_s = ['r', 'g', 'b', 'y', 'm']\n",
    "    labels = ['NULL', 'Aspect', 'Opinion-POS', 'Opinion-NEU', 'Opinion-NEG']\n",
    "\n",
    "    gather_ = [i for i in gather if i.shape[0] != 0]\n",
    "    gather_n = [i.shape[0] for i in gather_]\n",
    "    c_s_ = [c_s[i] for i in range(len(gather)) if gather[i].shape[0] != 0]\n",
    "    labels_ = [labels[i] for i in range(len(gather)) if gather[i].shape[0] != 0]\n",
    "\n",
    "    N = 6 * min(gather_n)\n",
    "    \n",
    "    pca = PCA(n_components=2)\n",
    "\n",
    "    # pca.fit(gathered_token_class_0)\n",
    "\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "\n",
    "    # print(len(gather_), len(c_s_), len(labels_), N)\n",
    "\n",
    "    for i, c, label in zip(gather_, c_s_, labels_):\n",
    "        i = i[np.random.choice(i.shape[0], min(N, i.shape[0]), replace=False), :]\n",
    "        pca.fit(i)\n",
    "        pca_i = pca.transform(i)\n",
    "        ax.scatter(pca_i[:,0], pca_i[:,1], c=c, label=label)\n",
    "\n",
    "    plt.legend()\n",
    "    plt.savefig(f'./plots_saved/pca_2d_{datetime.datetime.today()}_{epoch}.png')\n",
    "\n",
    " \n",
    "def plot_pca_3d(gathered_token_class_0, gathered_token_class_1, gathered_token_class_2, gathered_token_class_3, gathered_token_class_4, epoch):\n",
    "    # random sample N points for each class, where N is the number of points in the smallest class\n",
    "    gather = [gathered_token_class_0, \n",
    "            gathered_token_class_1, \n",
    "            gathered_token_class_2, \n",
    "            gathered_token_class_3, \n",
    "            gathered_token_class_4]\n",
    "    c_s = ['r', 'g', 'b', 'y', 'm']\n",
    "    labels = ['NULL', 'Aspect', 'Opinion-POS', 'Opinion-NEU', 'Opinion-NEG']\n",
    "\n",
    "    gather_ = [i for i in gather if i.shape[0] != 0]\n",
    "    gather_n = [i.shape[0] for i in gather_]\n",
    "    c_s_ = [c_s[i] for i in range(len(gather)) if gather[i].shape[0] != 0]\n",
    "    labels_ = [labels[i] for i in range(len(gather)) if gather[i].shape[0] != 0]\n",
    "\n",
    "    N = 6 * min(gather_n)\n",
    "    \n",
    "    pca = PCA(n_components=3)\n",
    "\n",
    "    # pca.fit(gathered_token_class_0)\n",
    "\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "    # print(len(gather_), len(c_s_), len(labels_), N)\n",
    "\n",
    "    for i, c, label in zip(gather_, c_s_, labels_):\n",
    "        i = i[np.random.choice(i.shape[0], min(N, i.shape[0]), replace=False), :]\n",
    "        pca.fit(i)\n",
    "        pca_i = pca.transform(i)\n",
    "        ax.scatter(pca_i[:,0], pca_i[:,1], pca_i[:,2], c=c, label=label)\n",
    "\n",
    "    plt.legend()\n",
    "    plt.savefig(f'./plots_saved/pca_3d_{datetime.datetime.today()}_{epoch}.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "absa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
